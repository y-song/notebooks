{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(inputFiles):\n",
    "    cols = []\n",
    "    scalar = []\n",
    "    scalar.append('evid')\n",
    "    scalar.append('xsec')\n",
    "    scalar.append('ntrials')    \n",
    "    scalar.append('x')\n",
    "    scalar.append('y')\n",
    "    scalar.append('Q2')\n",
    "    scalar.append('W2')\n",
    "    scalar.append('pt_jet')\n",
    "    scalar.append('eta_jet')\n",
    "    scalar.append('phi_jet')\n",
    "    scalar.append('pt_quark')\n",
    "    scalar.append('eta_quark')\n",
    "    scalar.append('phi_quark')\n",
    "    scalar.append('pt_photon')\n",
    "    scalar.append('phi_photon')\n",
    "    scalar.append('eta_electron')\n",
    "    scalar.append('pt_electron')\n",
    "    scalar.append('phi_electron')\n",
    "    lists = scalar\n",
    "    dataframes = []\n",
    "    for inputFilename in inputFiles:\n",
    "        start = time.time()\n",
    "        df = read_root(inputFilename, columns=lists,flatten=cols)\n",
    "        dataframes.append(df)\n",
    "        end = time.time()\n",
    "        print '\\n', 'Processed', inputFilename, 'in',  '%2.1f'%(end-start), 'seconds'\n",
    "    return pd.concat([x for x in dataframes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def polar(Q2Index, xIndex, r_low, theta_low, part_low, r_high, theta_high, color):\n",
    "    if xIndex > 4 and Q2Index > 0:\n",
    "        radii = radii_large\n",
    "        r_labels = r_labels_large\n",
    "        nr = nr_large\n",
    "    else:    \n",
    "        radii = radii_small\n",
    "        r_labels = r_labels_small\n",
    "        nr = nr_small\n",
    "    r_edges = np.linspace(0, nr, nr + 1)\n",
    "    theta_edges = np.linspace(0, 2*np.pi, ntheta + 1)\n",
    "    H_e = plt.hist2d(r_high, theta_high, [r_edges, theta_edges])[0]\n",
    "    H_q = plt.hist2d(r_low, theta_low, [r_edges, theta_edges])[0]\n",
    "    plt.cla()\n",
    "    \n",
    "    Theta, R = np.meshgrid(theta_edges, r_edges)\n",
    "    im_e = plt.pcolormesh(Theta, R, H_e, cmap='Blues', norm=LogNorm())\n",
    "    im_q = plt.pcolormesh(Theta, R, H_q, cmap=color, norm=LogNorm())\n",
    "    plt.rgrids(radii, labels=r_labels, fontsize=20)\n",
    "    plt.thetagrids(angles, labels=eta_labels, fontsize=20)\n",
    "    plt.grid(color='grey')\n",
    "    cbar_e = plt.colorbar(im_e, shrink=0.7, pad=0.01, cax=plt.axes([0.85, 0.55, 0.03, 0.3]))\n",
    "    cbar_e.ax.tick_params(labelsize=20)\n",
    "    cbar_q = plt.colorbar(im_q, shrink=0.7, pad=0.01, cax=plt.axes([0.85, 0.2, 0.03, 0.3]))\n",
    "    cbar_q.ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def getDataPart(inputFiles):\n",
    "    cols = []\n",
    "    scalar = []\n",
    "    scalar.append('evid')\n",
    "    scalar.append('xsec')\n",
    "    scalar.append('ntrials')    \n",
    "    scalar.append('x')\n",
    "    scalar.append('y')\n",
    "    scalar.append('Q2')\n",
    "    scalar.append('W2')\n",
    "    scalar.append('id_quark')\n",
    "    scalar.append('pt_quark')\n",
    "    scalar.append('eta_quark')\n",
    "    scalar.append('eta_electron')\n",
    "    cols.append('jetid')\n",
    "    cols.append('pt_jet')\n",
    "    cols.append('eta_jet')\n",
    "    cols.append('id_lead_part')\n",
    "    cols.append('id_part')\n",
    "    cols.append('pT_part')\n",
    "    cols.append('eta_part')\n",
    "    cols.append('theta_part')\n",
    "    lists = scalar + cols\n",
    "    dataframes = []\n",
    "    for inputFilename in inputFiles:\n",
    "        start = time.time()\n",
    "        df = read_root(inputFilename, columns=lists,flatten=cols)\n",
    "        dataframes.append(df)\n",
    "        end = time.time()\n",
    "        print '\\n', 'Processed', inputFilename, 'in',  '%2.1f'%(end-start), 'seconds'\n",
    "    return pd.concat([x for x in dataframes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParticle(array):\n",
    "    particle_array = []\n",
    "    for array_element in array:\n",
    "        if (array_element == 2212):\n",
    "            particle_array.append('$p$/$\\overline{p}$')\n",
    "        elif (array_element == 2112):\n",
    "            particle_array.append('$n$/$\\overline{n}$')\n",
    "        elif (array_element == 321):\n",
    "            particle_array.append('$K^{+}$/$K^{-}$')\n",
    "        elif (array_element == 211):\n",
    "            particle_array.append('$\\pi^{+}$/$\\pi^{-}$')\n",
    "        elif (array_element == 130):\n",
    "            particle_array.append('$K^0_L$')\n",
    "        elif (array_element == 22):\n",
    "            particle_array.append('$\\gamma$')\n",
    "        elif (array_element == 16):\n",
    "            particle_array.append(r'$\\nu_T$/$\\overline{\\nu}_T$')\n",
    "        elif (array_element == 14):\n",
    "            particle_array.append(r'$\\nu_{\\mu}$/$\\overline{\\nu}_{\\mu}$')\n",
    "        elif (array_element == 13):\n",
    "            particle_array.append('$\\mu^{-}$/$\\mu^{+}$')\n",
    "        elif (array_element == 12):\n",
    "            particle_array.append(r'$\\nu_e$/$\\overline{\\nu}_e$')\n",
    "        elif (array_element == 11):\n",
    "            particle_array.append('$e^{-}$/$e^{+}$')\n",
    "        else:\n",
    "            particle_array.append(str(array_element))\n",
    "    return particle_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuark(array):\n",
    "    particle_array = []\n",
    "    for array_element in array:\n",
    "        if (array_element == -5 or array_element == 5):\n",
    "            particle_array.append('$b$/$\\overline{b}$')\n",
    "        elif (array_element == -4 or array_element == 4):\n",
    "            particle_array.append('$c$/$\\overline{c}$')\n",
    "        elif (array_element == -3 or array_element == 3):\n",
    "            particle_array.append('$s$/$\\overline{s}$')\n",
    "        elif (array_element == -2):\n",
    "            particle_array.append('$\\overline{u}$')\n",
    "        elif (array_element == -1):\n",
    "            particle_array.append('$\\overline{d}$')\n",
    "        elif (array_element == 1):\n",
    "            particle_array.append('$d$')\n",
    "        elif (array_element == 2):\n",
    "            particle_array.append('$u$')\n",
    "        else:\n",
    "            particle_array.append(str(array_element))\n",
    "    return particle_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIdAndCounts(df, var, other=True):\n",
    "    b = df.groupby(var).count()\n",
    "    id_table = np.array([b.index,b['Q2']])\n",
    "    if other == False:\n",
    "        return id_table\n",
    "    else:\n",
    "        other_count_tot = 0\n",
    "        other_id_array = []\n",
    "        other_count_array = []\n",
    "        remove_array = []\n",
    "        for i in range(0, len(id_table[0])):\n",
    "            if float(id_table[1][i])/sum(id_table[1]) < 0.01:\n",
    "                other_id_array.append(id_table[0][i])\n",
    "                other_count_array.append(id_table[1][i])\n",
    "                other_count_tot += id_table[1][i]\n",
    "                remove_array.append(i)\n",
    "        id_table = np.delete(id_table, remove_array, 1)\n",
    "        other_id_table = np.array([other_id_array, other_count_array])\n",
    "        return id_table, other_id_table, other_count_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRanges(edges):\n",
    "    return zip(edges[:-1], edges[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCut(inputDataframe, cut, text=None):\n",
    "    dataframe = inputDataframe\n",
    "    nbeforecut = dataframe.shape[0]\n",
    "    cutDataframe = dataframe.query(cut)\n",
    "    if text:\n",
    "        print text, cutDataframe.shape[0], ' fraction kept: %2.1f'%(100.0*float(cutDataframe.shape[0])/nbeforecut)\n",
    "    return cutDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCuts(df, xedges, Q2edges):\n",
    "    xranges = getRanges(xedges)\n",
    "    Q2ranges = getRanges(Q2edges)\n",
    "    ds = [['' for j in range(0,len(xranges))] for i in range(0,len(Q2ranges))]\n",
    "    for i in range(0,len(Q2ranges)):\n",
    "        Q2low, Q2high = Q2ranges[i]\n",
    "        print '\\n', str(Q2low) +' < Q2 < '+ str(Q2high) +' GeV2', '\\n'\n",
    "        ds_Q2 = applyCut(df, 'Q2 > ' + str(Q2low) + 'and Q2 < ' + str(Q2high), str(Q2low) + ' < Q2 < ' + str(Q2high))\n",
    "        for j in range(0,len(xranges)):\n",
    "            xlow, xhigh = xranges[j]\n",
    "            ds_Q2_x = applyCut(ds_Q2, 'x > ' + str(xlow) + 'and x < ' + str(xhigh), str(xlow) + ' < x < ' + str(xhigh))\n",
    "            ds[i][j] = ds_Q2_x\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionEtaPt(df, etaedges, ptranges):\n",
    "    etaranges = getRanges(etaedges)\n",
    "    ptranges = getRanges(ptranges)\n",
    "    ds = [['' for j in range(0,len(ptranges))] for i in range(0,len(etaranges))]\n",
    "    for i in range(0,len(etaranges)):\n",
    "        etalow, etahigh = etaranges[i]\n",
    "        print '\\n', str(etalow) +' < eta_jet < '+ str(etahigh), '\\n'\n",
    "        ds_eta = applyCut(df, 'eta_jet> ' + str(etalow) + 'and eta_jet < ' + str(etahigh), str(etalow) + ' < eta_jet < ' + str(etahigh))\n",
    "        for j in range(0,len(ptranges)):\n",
    "            ptlow, pthigh = ptranges[j]\n",
    "            ds_eta_pt = applyCut(ds_eta, 'pt_jet > ' + str(ptlow) + 'and pt_jet < ' + str(pthigh), str(ptlow) + ' < pt_jet < ' + str(pthigh))\n",
    "            ds[i][j] = ds_eta_pt\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumber(ds):\n",
    "    matrix = [['' for j in range(0,len(ptedges)-1)] for i in range(0,len(etaedges)-1)]\n",
    "    for i in range(0,len(etaedges)-1):\n",
    "        for j in range(0,len(ptedges)-1):\n",
    "            matrix[i][j] = ds[i][j].shape[0]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionEta(df, etaedges):\n",
    "    etaranges = getRanges(etaedges)\n",
    "    ds = ['' for i in range(0,len(etaranges))]\n",
    "    for i in range(0,len(etaranges)):\n",
    "        etalow, etahigh = etaranges[i]\n",
    "        print '\\n', str(etalow) +' < eta_jet < '+ str(etahigh), '\\n'\n",
    "        ds[i] = applyCut(df, 'eta_jet> ' + str(etalow) + 'and eta_jet < ' + str(etahigh), str(etalow) + ' < eta_jet < ' + str(etahigh))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keepOneJet(inputDataframe):    \n",
    "    dataframe = inputDataframe\n",
    "    nbeforecut = dataframe.shape[0]\n",
    "    cutDataframe = dataframe.loc[~dataframe['evid'].duplicated(keep='first')]\n",
    "    print '\\n','Remove extra jets',cutDataframe.shape[0],' fraction kept: %2.1f'%(100.0*float(cutDataframe.shape[0])/nbeforecut)\n",
    "    return cutDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keepOnePart(inputDataframe):    \n",
    "    dataframe = inputDataframe\n",
    "    nbeforecut = dataframe.shape[0]\n",
    "    cutDataframe = dataframe.loc[~dataframe['jetid'].duplicated(keep='first')]\n",
    "    print '\\n','Remove extra part',cutDataframe.shape[0],' fraction kept: %2.1f'%(100.0*float(cutDataframe.shape[0])/nbeforecut)\n",
    "    return cutDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't work\n",
    "def fixPhi(df_o, particle, groomed=False):\n",
    "    df = df_o\n",
    "    if groomed == True:\n",
    "        string = 'phi_jet_g'\n",
    "    else:\n",
    "        string = 'phi_jet'\n",
    "    a = (df.loc[df['phi_' + particle] < 0]).index # a list of row indices (jet id) with negative phi_photon values\n",
    "    for i in range(0,len(a)):\n",
    "        df.at[a[i],'phi_' + particle] = df.at[a[i],'phi_' + particle] + 6.28318530718\n",
    "    print 'Fixed ' + particle + ' phi range'\n",
    "    eq = 'delta_phi_' + particle + ' = phi_' + particle + ' - ' + string\n",
    "    df.eval(eq, inplace=True)\n",
    "    b = (df.loc[df['delta_phi_' + particle] > np.pi]).index\n",
    "    for i in range(0,len(b)):\n",
    "        df.at[b[i],'delta_phi_' + particle] = -6.28318530718 + df.at[b[i],'delta_phi_' + particle]\n",
    "    c = (df.loc[df['delta_phi_' + particle] < (-1) * np.pi]).index\n",
    "    for i in range(0,len(c)):\n",
    "        df.at[c[i],'delta_phi_' + particle] = 6.28318530718 + df.at[c[i],'delta_phi_' + particle]\n",
    "    df.eval('delta_phi_' + particle + '_abs = abs(delta_phi_' + particle + ')', inplace=True)    \n",
    "    print 'Fixed ' + particle + ' delta phi range'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixPhi(df, particle, groomed=False):\n",
    "    if groomed == True:\n",
    "        string = 'phi_jet_g'\n",
    "    else:\n",
    "        string = 'phi_jet'\n",
    "    a = (df.loc[df['phi_' + particle] < 0]).index # a list of row indices (jet id) with negative phi_photon values\n",
    "    for i in range(0,len(a)):\n",
    "        df.at[a[i],'phi_' + particle] = df.at[a[i],'phi_' + particle] + 6.28318530718\n",
    "    print 'Fixed ' + particle + ' phi range'\n",
    "    df_new = df.eval('delta_phi_' + particle + ' = phi_' + particle + ' - ' + string)\n",
    "    b = (df_new.loc[df_new['delta_phi_' + particle] > np.pi]).index\n",
    "    for i in range(0,len(b)):\n",
    "        df_new.at[b[i],'delta_phi_' + particle] = -6.28318530718 + df_new.at[b[i],'delta_phi_' + particle]\n",
    "    c = (df_new.loc[df_new['delta_phi_' + particle] < (-1) * np.pi]).index\n",
    "    for i in range(0,len(c)):\n",
    "        df_new.at[c[i],'delta_phi_' + particle] = 6.28318530718 + df_new.at[c[i],'delta_phi_' + particle]\n",
    "    df_new_new = df_new.eval('delta_phi_' + particle + '_abs = abs(delta_phi_' + particle + ')')    \n",
    "    print 'Fixed ' + particle + ' delta phi range'\n",
    "    return df_new_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIdAbs(df, var, array):\n",
    "    for array_element in array:\n",
    "        a = (df.loc[df[var] == array_element]).index\n",
    "        for i in range(0,len(a)):\n",
    "            df.at[a[i], var] = abs(df.at[a[i],var])\n",
    "        print var + ' of ' + str(array_element) + ' is changed to positive'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDelta(df, particle):\n",
    "    df.eval('delta_eta_' + particle + ' = eta_' + particle + ' - eta_jet', inplace=True)\n",
    "    df.eval('delta_pt_' + particle + ' = pt_' + particle + ' - pt_jet', inplace=True)\n",
    "    df.eval('delta_eta_' + particle + '_abs = abs(delta_eta_' + particle + ')', inplace=True)    \n",
    "    df.eval('delta_pt_' + particle + '_abs = abs(delta_pt_' + particle + ')', inplace=True)    \n",
    "    print 'Added colomns for variables of ' + particle + ' jet correlation'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toStr(inputArray):\n",
    "    length = inputArray.size\n",
    "    array = []\n",
    "    for i in range(0,length):\n",
    "        array.append(str(inputArray[i])) \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toArrayFloat(begin, end, interval=0, log=False, logNum=0):\n",
    "    array = []\n",
    "    if log==True:\n",
    "        array = np.logspace(begin, end, num=logNum)\n",
    "    else:\n",
    "        length = int((end - begin) / interval + 1)\n",
    "        for i in range(0,length):\n",
    "            array.append((float(begin + interval * i))) \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toArray(begin, end, interval=0, log=False, logNum=0):\n",
    "    array = []\n",
    "    if log==True:\n",
    "        array_float = np.logspace(begin, end, num=logNum)\n",
    "        array = toStr(array_float)\n",
    "    else:\n",
    "        length = int((end - begin) / interval + 1)\n",
    "        for i in range(0,length):\n",
    "            array.append(str(float(begin + interval * i))) \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins(df, variable, begin, end, interval=0, log=False, logNum=0):  \n",
    "    ds=[]\n",
    "    array = toArray(begin, end, interval, log, logNum)\n",
    "    for i in range(0,len(array)-1):\n",
    "        ds.append(df.query('' + str(variable) + ' > ' + str(array[i]) + ' and ' + str(variable) + ' < ' + str(array[i+1]) + ''))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInterval(arrayFloat):\n",
    "    interval = np.zeros(len(arrayFloat)-1)\n",
    "    for i in range(0,len(arrayFloat)-1):\n",
    "        interval[i] = arrayFloat[i+1] - arrayFloat[i]\n",
    "    return interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(counts, dataframeBeforeCut):\n",
    "    xsec = np.mean(dataframeBeforeCut['xsec'])\n",
    "    ntrials = dataframeBeforeCut['ntrials'][dataframeBeforeCut.shape[0]-1]\n",
    "    return 10 * (counts * xsec * 1e12) / ntrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot1d(df, var, low, high, bottom, top, interval, xlabel, yscale, title, txt):\n",
    "\n",
    "    xvar_array = toArrayFloat(low, high, interval)\n",
    "    xsec = np.mean(a['xsec'])\n",
    "    ntrials = a['ntrials'][a.shape[0]-1]\n",
    "    \n",
    "    x, y, xerr = getHist(df, var, xvar_array)\n",
    "       \n",
    "    plt.errorbar(x, 10*y*xsec*1e12/ntrials, xerr = xerr, fmt='none', color='b', elinewidth=1)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.yscale(yscale)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel('$d\\sigma*10fb^{-1}$', fontsize=15)\n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.xlim(left=low, right=high)\n",
    "    plt.ylim(bottom=bottom, top=top)\n",
    "    plt.legend(prop={'size': 12.5}, frameon=False, loc='best')\n",
    "    plt.savefig('images/' + txt + '.pdf', bbox='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot2d(df, xvar, yvar, xlabel, ylabel, title=None, lim=None):\n",
    "\n",
    "    plt.hexbin(df[xvar], df[yvar], gridsize=50, norm=LogNorm(), cmap='inferno', xscale = 'log', extent=lim)\n",
    "    plt.xlabel(xlabel, fontsize = 15)\n",
    "    plt.ylabel(ylabel, fontsize = 15)\n",
    "    plt.tick_params(labelsize='large')\n",
    "    plt.colorbar()\n",
    "    if title != None:\n",
    "        plt.title('$' + title + '$', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHist(df, var, binEdges):\n",
    "        \n",
    "    x = []\n",
    "    for i in range(0,len(binEdges)-1):\n",
    "        x.append((binEdges[i] + binEdges[i+1]) / 2)\n",
    "    \n",
    "    y = np.histogram(df[var], bins=binEdges)[0]\n",
    "    \n",
    "    xerr = getInterval(binEdges)/2\n",
    "    \n",
    "    return x, y, xerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(array):\n",
    "    s = 0\n",
    "    for element in array:\n",
    "        s = s + element**2\n",
    "    if len(array) == 0:\n",
    "        rms = 0\n",
    "    else:\n",
    "        rms = np.sqrt(s/len(array))\n",
    "    return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot1dnvar(df_array, var_array, label_array, low, high, bottom, top, interval, xlabel, yscale, txt):\n",
    "    \n",
    "    color_array = ['r', 'g', 'b', 'purple']\n",
    "    xvar_array = toArrayFloat(low, high, interval)\n",
    "    xsec = np.mean(a['xsec'])\n",
    "    ntrials = a['ntrials'][a.shape[0]-1]\n",
    "    \n",
    "    for i in range(0, len(df_array)):\n",
    "        x, y, xerr = getHist(df_array[i], var_array[i], xvar_array)\n",
    "        plt.errorbar(x, 10*y*xsec*1e12/ntrials, xerr = xerr, fmt='none', color=color_array[i],elinewidth=2,label=label_array[i])\n",
    "   \n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.yscale(yscale)\n",
    "    plt.xlabel(xlabel, fontsize=20)\n",
    "    plt.ylabel('$d\\sigma*10fb^{-1}$', fontsize=20)\n",
    "    #plt.title(title, fontsize=15)\n",
    "    plt.xlim(left=low, right=high)\n",
    "    plt.yscale(yscale)\n",
    "    plt.legend(prop={'size': 20}, frameon=False,loc='upper right')\n",
    "    plt.savefig('images/' + txt + '.pdf', bbox='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(binwidth, yarray, low, high):\n",
    "    s = 0\n",
    "    interval = (int)((high - low)/binwidth)\n",
    "    for i in range(0, interval):\n",
    "        s = s + binwidth * yarray[i]\n",
    "    return s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
